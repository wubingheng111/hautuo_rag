"""
å¿ƒè¡€ç®¡ç–¾ç—…ä¸“ç§‘æ¨¡å—
ä¸“é—¨å¤„ç†å¿ƒè¡€ç®¡ç›¸å…³çš„åŒ»å­¦é—®ç­”
åŸºäºåä½—æ•°æ®é›†çš„å¿ƒè¡€ç®¡ä¸“é¡¹æ•°æ®
"""
import re
import json
import numpy as np
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

@dataclass
class CardiovascularRiskFactor:
    """å¿ƒè¡€ç®¡é£é™©å› ç´ """
    name: str
    category: str  # 'modifiable' or 'non_modifiable'
    severity: str  # 'low', 'medium', 'high'
    description: str

class CardiovascularSpecialist:
    """å¿ƒè¡€ç®¡ç–¾ç—…ä¸“ç§‘å¤„ç†å™¨"""

    def __init__(self):
        self.cardio_keywords = self._load_cardio_keywords()
        self.risk_factors = self._load_risk_factors()
        self.emergency_keywords = self._load_emergency_keywords()
        self.knowledge_base = None
        self.vector_store = None

    def _load_cardio_keywords(self) -> Dict[str, List[str]]:
        """åŠ è½½å¿ƒè¡€ç®¡å…³é”®è¯åº“"""
        return {
            "ç–¾ç—…": [
                "å† å¿ƒç—…", "å¿ƒè‚Œæ¢—æ­»", "å¿ƒç»ç—›", "é«˜è¡€å‹", "ä½è¡€å‹",
                "å¿ƒå¾‹ä¸é½", "å¿ƒæˆ¿é¢¤åŠ¨", "å¿ƒåŠ›è¡°ç«­", "å¿ƒè‚Œç—…", "å¿ƒåŒ…ç‚",
                "åŠ¨è„‰ç¡¬åŒ–", "åŠ¨è„‰ç˜¤", "é™è„‰æ›²å¼ ", "è¡€æ “", "æ “å¡",
                "å¿ƒè„ç—…", "å…ˆå¿ƒç—…", "é£å¿ƒç—…", "è‚ºå¿ƒç—…"
            ],
            "ç—‡çŠ¶": [
                "èƒ¸ç—›", "èƒ¸é—·", "å¿ƒæ‚¸", "æ°”çŸ­", "å‘¼å¸å›°éš¾",
                "å¤´æ™•", "æ™•å¥", "æ°´è‚¿", "ä¹åŠ›", "å¿ƒæ…Œ",
                "èƒ¸éƒ¨ä¸é€‚", "å¿ƒè·³å¿«", "å¿ƒè·³æ…¢", "å¿ƒè·³ä¸è§„å¾‹"
            ],
            "æ£€æŸ¥": [
                "å¿ƒç”µå›¾", "å¿ƒè„å½©è¶…", "å† è„‰é€ å½±", "å¿ƒè‚Œé…¶", "è‚Œé’™è›‹ç™½",
                "è¡€å‹", "è¡€è„‚", "å¿ƒç‡", "åŠ¨æ€å¿ƒç”µå›¾", "è¿åŠ¨è¯•éªŒ",
                "CTè¡€ç®¡é€ å½±", "æ ¸ç£å…±æŒ¯", "å¿ƒå¯¼ç®¡"
            ],
            "è¯ç‰©": [
                "é™å‹è¯", "ç¡é…¸ç”˜æ²¹", "é˜¿å¸åŒ¹æ—", "ä»–æ±€", "Î²å—ä½“é˜»æ»å‰‚",
                "ACEæŠ‘åˆ¶å‰‚", "ARB", "åˆ©å°¿å‰‚", "é’™é€šé“é˜»æ»å‰‚",
                "æŠ—å‡è¯", "æŠ—è¡€å°æ¿", "å¼ºå¿ƒè¯", "æŠ—å¿ƒå¾‹å¤±å¸¸è¯"
            ],
            "æ²»ç–—": [
                "æ”¯æ¶", "æ­æ¡¥", "çƒå›Šæ‰©å¼ ", "èµ·æå™¨", "é™¤é¢¤å™¨",
                "å°„é¢‘æ¶ˆè", "å¿ƒè„ç§»æ¤", "ä»‹å…¥æ²»ç–—", "æ‰‹æœ¯æ²»ç–—"
            ]
        }

    def _load_risk_factors(self) -> List[CardiovascularRiskFactor]:
        """åŠ è½½å¿ƒè¡€ç®¡é£é™©å› ç´ """
        return [
            # ä¸å¯æ§å› ç´ 
            CardiovascularRiskFactor("å¹´é¾„", "non_modifiable", "high", "ç”·æ€§â‰¥45å²ï¼Œå¥³æ€§â‰¥55å²"),
            CardiovascularRiskFactor("æ€§åˆ«", "non_modifiable", "medium", "ç”·æ€§é£é™©é«˜äºå¥³æ€§"),
            CardiovascularRiskFactor("å®¶æ—å²", "non_modifiable", "high", "ç›´ç³»äº²å±æœ‰æ—©å‘å¿ƒè¡€ç®¡ç–¾ç—…"),

            # å¯æ§å› ç´ 
            CardiovascularRiskFactor("å¸çƒŸ", "modifiable", "high", "å¸çƒŸæ˜¯æœ€é‡è¦çš„å¯æ§å±é™©å› ç´ "),
            CardiovascularRiskFactor("é«˜è¡€å‹", "modifiable", "high", "æ”¶ç¼©å‹â‰¥140mmHgæˆ–èˆ’å¼ å‹â‰¥90mmHg"),
            CardiovascularRiskFactor("ç³–å°¿ç—…", "modifiable", "high", "è¡€ç³–æ§åˆ¶ä¸è‰¯"),
            CardiovascularRiskFactor("è¡€è„‚å¼‚å¸¸", "modifiable", "high", "LDL-Cå‡é«˜ï¼ŒHDL-Cé™ä½"),
            CardiovascularRiskFactor("è‚¥èƒ–", "modifiable", "medium", "BMIâ‰¥28æˆ–è…°å›´è¿‡å¤§"),
            CardiovascularRiskFactor("ç¼ºä¹è¿åŠ¨", "modifiable", "medium", "ä¹…åä¸åŠ¨çš„ç”Ÿæ´»æ–¹å¼"),
            CardiovascularRiskFactor("ä¸è‰¯é¥®é£Ÿ", "modifiable", "medium", "é«˜ç›ã€é«˜è„‚ã€é«˜ç³–é¥®é£Ÿ"),
            CardiovascularRiskFactor("æ…¢æ€§å‹åŠ›", "modifiable", "medium", "é•¿æœŸç²¾ç¥ç´§å¼ "),
            CardiovascularRiskFactor("ç¡çœ ä¸è¶³", "modifiable", "low", "ç¡çœ è´¨é‡å·®")
        ]

    def _load_emergency_keywords(self) -> List[str]:
        """åŠ è½½æ€¥ç—‡å…³é”®è¯"""
        return [
            "èƒ¸ç—›å‰§çƒˆ", "èƒ¸ç—›æŒç»­", "å‹æ¦¨æ€§èƒ¸ç—›", "æ’•è£‚æ ·èƒ¸ç—›",
            "å‘¼å¸å›°éš¾åŠ é‡", "ä¸èƒ½å¹³å§", "å¤§æ±—æ·‹æ¼“", "é¢è‰²è‹ç™½",
            "æ„è¯†æ¨¡ç³Š", "æ™•å¥", "å¿ƒè·³åœæ­¢", "è¡€å‹ä¸‹é™",
            "æ€¥æ€§", "çªå‘", "å‰§çƒˆ", "æŒç»­ä¸ç¼“è§£"
        ]

    def is_cardiovascular_related(self, text: str) -> Dict[str, Any]:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¿ƒè¡€ç®¡ç›¸å…³é—®é¢˜"""
        text_lower = text.lower()

        # ç»Ÿè®¡å„ç±»å…³é”®è¯å‡ºç°æ¬¡æ•°
        category_scores = {}
        matched_keywords = {}

        for category, keywords in self.cardio_keywords.items():
            score = 0
            matched = []

            for keyword in keywords:
                if keyword in text_lower:
                    score += 1
                    matched.append(keyword)

            category_scores[category] = score
            matched_keywords[category] = matched

        # è®¡ç®—æ€»åˆ†å’Œç½®ä¿¡åº¦
        total_score = sum(category_scores.values())
        confidence = min(total_score / 10.0, 1.0)  # å½’ä¸€åŒ–åˆ°0-1

        # åˆ¤æ–­æ˜¯å¦ä¸ºå¿ƒè¡€ç®¡ç›¸å…³
        is_cardio = confidence > 0.3 or any(score > 0 for score in category_scores.values())

        return {
            "is_cardiovascular": is_cardio,
            "confidence": confidence,
            "category_scores": category_scores,
            "matched_keywords": matched_keywords,
            "total_matches": total_score
        }

    def assess_emergency_level(self, text: str) -> Dict[str, Any]:
        """è¯„ä¼°æ€¥ç—‡ç¨‹åº¦"""
        emergency_score = 0
        matched_emergency = []

        for keyword in self.emergency_keywords:
            if keyword in text:
                emergency_score += 1
                matched_emergency.append(keyword)

        # ç‰¹æ®Šæ€¥ç—‡æ¨¡å¼æ£€æµ‹
        emergency_patterns = [
            r"èƒ¸ç—›.*æŒç»­.*\d+.*å°æ—¶",
            r"èƒ¸ç—›.*æ”¾å°„.*å·¦è‡‚",
            r"å‘¼å¸å›°éš¾.*ä¸èƒ½.*å¹³å§",
            r"è¡€å‹.*\d+.*\d+.*å¾ˆé«˜",
            r"å¿ƒè·³.*åœæ­¢|å¿ƒè„.*åœè·³"
        ]

        pattern_matches = 0
        for pattern in emergency_patterns:
            if re.search(pattern, text):
                pattern_matches += 1

        # è®¡ç®—æ€¥ç—‡ç­‰çº§
        total_emergency_score = emergency_score + pattern_matches * 2

        if total_emergency_score >= 3:
            level = "high"
            recommendation = "ğŸš¨ å»ºè®®ç«‹å³å°±åŒ»æˆ–æ‹¨æ‰“120æ€¥æ•‘ç”µè¯"
        elif total_emergency_score >= 1:
            level = "medium"
            recommendation = "âš ï¸ å»ºè®®å°½å¿«åˆ°åŒ»é™¢å¿ƒå†…ç§‘å°±è¯Š"
        else:
            level = "low"
            recommendation = "ğŸ’¡ å¯å…ˆè¿›è¡Œå’¨è¯¢ï¼Œå¿…è¦æ—¶å°±åŒ»"

        return {
            "emergency_level": level,
            "emergency_score": total_emergency_score,
            "matched_keywords": matched_emergency,
            "recommendation": recommendation
        }

    def analyze_risk_factors(self, text: str) -> Dict[str, Any]:
        """åˆ†æå¿ƒè¡€ç®¡é£é™©å› ç´ """
        mentioned_factors = []

        # æ£€æµ‹æ–‡æœ¬ä¸­æåˆ°çš„é£é™©å› ç´ 
        for factor in self.risk_factors:
            if any(keyword in text for keyword in [factor.name, factor.description]):
                mentioned_factors.append(factor)

        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
        high_risk = [f for f in mentioned_factors if f.severity == "high"]
        medium_risk = [f for f in mentioned_factors if f.severity == "medium"]
        low_risk = [f for f in mentioned_factors if f.severity == "low"]

        # è®¡ç®—æ€»ä½“é£é™©ç­‰çº§
        risk_score = len(high_risk) * 3 + len(medium_risk) * 2 + len(low_risk) * 1

        if risk_score >= 6:
            overall_risk = "high"
        elif risk_score >= 3:
            overall_risk = "medium"
        else:
            overall_risk = "low"

        return {
            "overall_risk": overall_risk,
            "risk_score": risk_score,
            "high_risk_factors": [f.name for f in high_risk],
            "medium_risk_factors": [f.name for f in medium_risk],
            "low_risk_factors": [f.name for f in low_risk],
            "modifiable_factors": [f.name for f in mentioned_factors if f.category == "modifiable"],
            "non_modifiable_factors": [f.name for f in mentioned_factors if f.category == "non_modifiable"]
        }

    def generate_cardio_prompt(self, question: str) -> str:
        """ç”Ÿæˆå¿ƒè¡€ç®¡ä¸“ç§‘æç¤ºè¯"""

        # åˆ†æé—®é¢˜ç‰¹å¾
        cardio_analysis = self.is_cardiovascular_related(question)
        emergency_analysis = self.assess_emergency_level(question)
        risk_analysis = self.analyze_risk_factors(question)

        # æ„å»ºä¸“ç§‘æç¤ºè¯
        prompt = f"""ä½ æ˜¯å¿ƒæ™ºåŒ»AIï¼Œä¸“é—¨çš„å¿ƒè¡€ç®¡ç–¾ç—…æ™ºèƒ½é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹åˆ†æå›ç­”ç”¨æˆ·çš„å¿ƒè¡€ç®¡ç›¸å…³é—®é¢˜ï¼š

é—®é¢˜åˆ†æï¼š
- å¿ƒè¡€ç®¡ç›¸å…³æ€§: {cardio_analysis['confidence']:.2f}
- æ€¥ç—‡ç­‰çº§: {emergency_analysis['emergency_level']}
- é£é™©è¯„ä¼°: {risk_analysis['overall_risk']}

{emergency_analysis['recommendation']}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š

1. **é—®é¢˜ç†è§£**: ç®€è¦åˆ†æç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒè¦ç‚¹
2. **ä¸“ä¸šè§£ç­”**: æä¾›å‡†ç¡®çš„å¿ƒè¡€ç®¡åŒ»å­¦ä¿¡æ¯
3. **é£é™©æç¤º**: å¦‚æœ‰å¿…è¦ï¼Œæé†’ç›¸å…³é£é™©å› ç´ 
4. **ç”Ÿæ´»å»ºè®®**: ç»™å‡ºå®ç”¨çš„ç”Ÿæ´»æ–¹å¼å»ºè®®
5. **å°±åŒ»æŒ‡å¯¼**: æ˜ç¡®æ˜¯å¦éœ€è¦å°±åŒ»åŠç§‘å®¤é€‰æ‹©

æ³¨æ„äº‹é¡¹ï¼š
- å¦‚æœæ˜¯æ€¥ç—‡æƒ…å†µï¼Œä¼˜å…ˆå¼ºè°ƒç´§æ€¥å°±åŒ»
- æä¾›çš„ä¿¡æ¯è¦å‡†ç¡®ã€ä¸“ä¸šä½†æ˜“æ‡‚
- å¼ºè°ƒè¿™æ˜¯å’¨è¯¢å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£åŒ»ç”Ÿè¯Šæ–­
- é‡ç‚¹å…³æ³¨å¿ƒè¡€ç®¡ç–¾ç—…çš„é¢„é˜²å’Œç®¡ç†

ç”¨æˆ·é—®é¢˜ï¼š{question}
"""

        return prompt

    def build_knowledge_base(self, cardio_data: List[Dict[str, Any]]):
        """æ„å»ºå¿ƒè¡€ç®¡çŸ¥è¯†åº“ï¼ˆæ”¯æŒå¢é‡æ›´æ–°ï¼‰"""
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–å¿ƒè¡€ç®¡çŸ¥è¯†å‘é‡æ•°æ®åº“...")

        try:
            from rag_system import MedicalRAGSystem
            from embeddings import EmbeddingManager

            # åˆå§‹åŒ–RAGç³»ç»Ÿå’ŒåµŒå…¥ç®¡ç†å™¨
            self.rag_system = MedicalRAGSystem()
            self.embedding_manager = EmbeddingManager()

            # æ£€æŸ¥ç°æœ‰æ•°æ®åº“çŠ¶æ€
            existing_stats = self.embedding_manager.get_collection_stats()
            existing_count = existing_stats.get('total_documents', 0)

            print(f"ğŸ“Š ç°æœ‰å‘é‡æ•°æ®åº“çŠ¶æ€: {existing_count} æ¡è®°å½•")

            # å¦‚æœæ•°æ®åº“å·²æœ‰è¶³å¤Ÿçš„å¿ƒè¡€ç®¡æ•°æ®ï¼Œè·³è¿‡é‡å»º
            expected_count = len(cardio_data)
            if existing_count >= expected_count * 0.95:  # å…è®¸5%çš„è¯¯å·®
                print(f"âœ… æ£€æµ‹åˆ°ç°æœ‰å¿ƒè¡€ç®¡çŸ¥è¯†åº“åŒ…å« {existing_count} æ¡è®°å½•")
                print(f"ğŸ“‹ é¢„æœŸè®°å½•æ•°: {expected_count}")
                print("ğŸš€ è·³è¿‡é‡å»ºï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰æ•°æ®åº“")
                self.knowledge_base = cardio_data
                return

            # å¦‚æœæ•°æ®ä¸å®Œæ•´æˆ–ä¸ºç©ºï¼Œé‡æ–°æ„å»º
            print(f"ğŸ”„ æ•°æ®åº“è®°å½•ä¸å®Œæ•´ ({existing_count}/{expected_count})ï¼Œå¼€å§‹é‡å»º...")

            # æ¸…ç©ºç°æœ‰é›†åˆï¼ˆå¦‚æœéœ€è¦ï¼‰
            if existing_count > 0:
                print("ğŸ—‘ï¸ æ¸…ç©ºç°æœ‰æ•°æ®...")
                self.embedding_manager.clear_collection()

            # å‡†å¤‡çŸ¥è¯†åº“æ•°æ® - ç®€åŒ–ä½†ä¼˜åŒ–çš„æ–¹æ³•
            documents = []
            for i, item in enumerate(cardio_data):
                question = item['question']
                answer = item['answer']
                keywords = item.get('matched_keywords', [])

                # æ™ºèƒ½æ–‡æœ¬å¢å¼ºï¼šä¸ºçŸ­æ–‡æœ¬æ·»åŠ ä¸Šä¸‹æ–‡ï¼Œé•¿æ–‡æœ¬ä¿æŒåŸæ ·
                if len(answer) < 30:  # æçŸ­ç­”æ¡ˆï¼ˆå¦‚"æ— ç‰¹æ®Šäººç¾¤"ï¼‰
                    # æ·»åŠ é—®é¢˜ä¸Šä¸‹æ–‡å’Œå…³é”®è¯
                    keyword_context = f" ç›¸å…³æ¦‚å¿µ: {', '.join(keywords[:3])}" if keywords else ""
                    enhanced_text = f"åŒ»å­¦é—®ç­”: {question} ç­”æ¡ˆ: {answer}{keyword_context}"
                elif len(answer) < 100:  # çŸ­ç­”æ¡ˆ
                    # ç®€å•å¢å¼º
                    enhanced_text = f"é—®é¢˜: {question} ç­”æ¡ˆ: {answer}"
                else:  # é•¿ç­”æ¡ˆï¼Œä¿æŒåŸæ ·
                    enhanced_text = f"é—®é¢˜: {question}\nç­”æ¡ˆ: {answer}"

                # åªåˆ›å»ºä¸€ä¸ªä¼˜åŒ–çš„æ–‡æ¡£
                documents.append({
                    "text": enhanced_text,
                    "chunk_id": f"cardio_{i:06d}",
                    "metadata": {
                        "question": question,
                        "answer": answer,
                        "keywords": ", ".join(keywords),
                        "keyword_count": len(keywords),
                        "source": "åä½—æ•°æ®é›†-å¿ƒè¡€ç®¡ä¸“é¡¹",
                        "dataset_info": "å¿ƒè¡€ç®¡ç–¾ç—…é—®ç­”æ•°æ®",
                        "data_type": "cardiovascular",
                        "text_length": len(enhanced_text),
                        "original_answer_length": len(answer)
                    }
                })

            # æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“
            self.embedding_manager.add_documents(documents)
            self.knowledge_base = cardio_data

            print(f"âœ… æˆåŠŸæ„å»ºåŒ…å« {len(documents)} æ¡è®°å½•çš„å¿ƒè¡€ç®¡çŸ¥è¯†åº“")
            print("ğŸ’¾ å‘é‡æ•°æ®åº“å·²æŒä¹…åŒ–ï¼Œä¸‹æ¬¡å¯åŠ¨å°†ç›´æ¥åŠ è½½")

        except Exception as e:
            print(f"âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
            raise

    def get_cardiovascular_answer(self, question: str, use_enhanced_rag: bool = True) -> Dict[str, Any]:
        """è·å–å¿ƒè¡€ç®¡ä¸“ç§‘å›ç­”"""

        if not self.knowledge_base:
            return {
                "answer": "âŒ å¿ƒè¡€ç®¡çŸ¥è¯†åº“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆæ„å»ºçŸ¥è¯†åº“",
                "confidence": 0.0,
                "references": []
            }

        try:
            # å¦‚æœå¯ç”¨å¢å¼ºRAGï¼Œä½¿ç”¨å®Œæ•´çš„RAGæµç¨‹
            if use_enhanced_rag:
                from enhanced_rag_system import EnhancedRAGSystem

                if not hasattr(self, 'enhanced_rag'):
                    self.enhanced_rag = EnhancedRAGSystem()

                # ä½¿ç”¨å¢å¼ºRAGç³»ç»Ÿè·å–å®Œæ•´çš„å¤„ç†ç»“æœ
                rag_result = self.enhanced_rag.query_with_full_process(question)

                # æ·»åŠ å¿ƒè¡€ç®¡ä¸“ç§‘åˆ†æ
                cardio_analysis = self.is_cardiovascular_related(question)
                emergency_analysis = self.assess_emergency_level(question)

                # å¦‚æœæ˜¯æ€¥ç—‡ï¼Œä¼˜å…ˆè¿”å›æ€¥ç—‡å»ºè®®
                if emergency_analysis['emergency_level'] == 'high':
                    rag_result['answer'] = f"ğŸš¨ {emergency_analysis['recommendation']}\n\n{rag_result['answer']}"
                    rag_result['emergency'] = True

                # æ·»åŠ å¿ƒè¡€ç®¡ä¸“ç§‘ä¿¡æ¯
                rag_result.update({
                    "cardio_confidence": cardio_analysis['confidence'],
                    "emergency_level": emergency_analysis['emergency_level'],
                    "emergency_recommendation": emergency_analysis['recommendation'],
                    "cardio_analysis": cardio_analysis
                })

                return rag_result

            else:
                # ä½¿ç”¨ç®€åŒ–çš„æ£€ç´¢æµç¨‹ï¼ˆå‘åå…¼å®¹ï¼‰
                return self._get_simple_answer(question)

        except Exception as e:
            return {
                "answer": f"å¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {e}",
                "confidence": 0.0,
                "references": [],
                "error": str(e)
            }

    def _get_simple_answer(self, question: str) -> Dict[str, Any]:
        """ç®€åŒ–çš„å›ç­”æµç¨‹ï¼ˆå‘åå…¼å®¹ï¼‰"""

        # åˆ†æé—®é¢˜ç‰¹å¾
        cardio_analysis = self.is_cardiovascular_related(question)
        emergency_analysis = self.assess_emergency_level(question)

        # å¦‚æœæ˜¯æ€¥ç—‡ï¼Œä¼˜å…ˆè¿”å›æ€¥ç—‡å»ºè®®
        if emergency_analysis['emergency_level'] == 'high':
            return {
                "answer": f"ğŸš¨ {emergency_analysis['recommendation']}\n\næ ¹æ®æ‚¨æè¿°çš„ç—‡çŠ¶ï¼Œè¿™å¯èƒ½æ˜¯å¿ƒè¡€ç®¡æ€¥ç—‡ã€‚è¯·ç«‹å³å°±åŒ»æˆ–æ‹¨æ‰“120æ€¥æ•‘ç”µè¯ï¼Œä¸è¦å»¶è¯¯æ²»ç–—æ—¶æœºã€‚",
                "confidence": 1.0,
                "emergency": True,
                "references": []
            }

        # ä½¿ç”¨å¢å¼ºæ£€ç´¢å™¨æ£€ç´¢ç›¸å…³ä¿¡æ¯
        from enhanced_retriever import EnhancedRetriever

        if not hasattr(self, 'enhanced_retriever'):
            self.enhanced_retriever = EnhancedRetriever()

        # ä½¿ç”¨å¢å¼ºæ£€ç´¢ï¼Œæ”¯æŒè°ƒè¯•æ¨¡å¼
        similar_docs = self.enhanced_retriever.search(question, top_k=8, debug=True)

        if not similar_docs:
            # å¦‚æœå¢å¼ºæ£€ç´¢ä¹Ÿæ²¡æ‰¾åˆ°ï¼Œå°è¯•æ›´å®½æ¾çš„æ£€ç´¢
            print("ğŸ”„ å°è¯•æ›´å®½æ¾çš„æ£€ç´¢ç­–ç•¥...")
            try:
                fallback_docs = self.embedding_manager.search_similar(
                    question,
                    top_k=10,
                    threshold=0.05  # éå¸¸å®½æ¾çš„é˜ˆå€¼
                )
                if fallback_docs:
                    similar_docs = fallback_docs
                    print(f"âœ… å¤‡ç”¨æ£€ç´¢æ‰¾åˆ° {len(fallback_docs)} æ¡ç»“æœ")
            except Exception as e:
                print(f"å¤‡ç”¨æ£€ç´¢ä¹Ÿå¤±è´¥: {e}")

        if not similar_docs:
            return {
                "answer": "æŠ±æ­‰ï¼Œæˆ‘åœ¨å¿ƒè¡€ç®¡çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºæ‚¨çš„é—®é¢˜æ¯”è¾ƒç‰¹æ®Šï¼Œå»ºè®®æ‚¨å’¨è¯¢ä¸“ä¸šçš„å¿ƒè¡€ç®¡ç§‘åŒ»ç”Ÿè·å¾—æ›´å‡†ç¡®çš„å»ºè®®ã€‚",
                "confidence": 0.0,
                "references": [],
                "search_info": {
                    "query": question,
                    "results_count": 0,
                    "search_strategies": ["enhanced", "fallback"]
                }
            }

        # æå–å‚è€ƒèµ„æ–™
        references = []
        for doc in similar_docs[:5]:  # å¢åŠ å‚è€ƒèµ„æ–™æ•°é‡
            if 'metadata' in doc:
                references.append({
                    "question": doc['metadata'].get('question', ''),
                    "answer": doc['metadata'].get('answer', ''),
                    "similarity": doc.get('final_score', doc.get('similarity', 0.0)),
                    "strategy": doc.get('strategy', 'unknown')
                })

        # ç”Ÿæˆä¸“ä¸šå›ç­”
        answer = self._generate_professional_answer(question, references, cardio_analysis, emergency_analysis)

        return {
            "answer": answer,
            "confidence": cardio_analysis['confidence'],
            "references": references,
            "emergency": emergency_analysis['emergency_level'] != 'low',
            "emergency_recommendation": emergency_analysis['recommendation'],
            "search_info": {
                "query": question,
                "results_count": len(similar_docs),
                "search_strategies": ["enhanced"] + (["fallback"] if len(similar_docs) > 8 else []),
                "top_similarity": similar_docs[0].get('final_score', similar_docs[0].get('similarity', 0)) if similar_docs else 0
            }
        }

    def _generate_professional_answer(self, question: str, references: List[Dict],
                                    cardio_analysis: Dict, emergency_analysis: Dict) -> str:
        """ç”Ÿæˆä¸“ä¸šçš„å¿ƒè¡€ç®¡å›ç­” - åŸºäºæ£€ç´¢ç»“æœè¿›è¡ŒçŸ¥è¯†æ‰©å±•"""

        # ä½¿ç”¨LLMè¿›è¡ŒçŸ¥è¯†æ‰©å±•
        try:
            from llm_client import LLMClient

            llm_client = LLMClient()

            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context_parts = []
            if references:
                context_parts.append("æ£€ç´¢åˆ°çš„ç›¸å…³åŒ»å­¦ä¿¡æ¯:")
                for i, ref in enumerate(references[:3], 1):
                    context_parts.append(f"{i}. é—®é¢˜: {ref['question']}")
                    context_parts.append(f"   ç­”æ¡ˆ: {ref['answer']}")
                    context_parts.append(f"   ç›¸ä¼¼åº¦: {ref.get('similarity', 0):.3f}")
                    context_parts.append("")

            context = "\n".join(context_parts)

            # æ„å»ºä¸“ä¸šçš„åŒ»å­¦æç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒè¡€ç®¡ç§‘åŒ»ç”ŸAIåŠ©æ‰‹ã€‚è¯·åŸºäºæ£€ç´¢åˆ°çš„åŒ»å­¦ä¿¡æ¯ï¼Œç»“åˆä½ çš„ä¸“ä¸šçŸ¥è¯†ï¼Œä¸ºæ‚£è€…æä¾›å…¨é¢ã€ä¸“ä¸šçš„å›ç­”ã€‚

è¦æ±‚ï¼š
1. åŸºäºæ£€ç´¢ç»“æœï¼Œä½†ä¸å±€é™äºæ£€ç´¢ç»“æœ
2. ç»“åˆåŒ»å­¦ä¸“ä¸šçŸ¥è¯†è¿›è¡Œæ‰©å±•è¯´æ˜
3. æä¾›å®ç”¨çš„å»ºè®®å’ŒæŒ‡å¯¼
4. ä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
5. åŒ…å«å¿…è¦çš„æ³¨æ„äº‹é¡¹å’Œå…è´£å£°æ˜

å›ç­”æ ¼å¼ï¼š
- ä½¿ç”¨æ¸…æ™°çš„ç»“æ„åŒ–æ ¼å¼
- åŒ…å«ä¸“ä¸šè§£é‡Šã€ç›¸å…³çŸ¥è¯†ã€æ³¨æ„äº‹é¡¹ç­‰
- è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œä½†ä¿æŒä¸“ä¸šæ€§"""

            # ç”Ÿæˆæ‰©å±•å›ç­”
            user_message = f"""
æ‚£è€…é—®é¢˜: {question}

å¿ƒè¡€ç®¡ç›¸å…³æ€§: {cardio_analysis['confidence']:.1%}
ç´§æ€¥ç¨‹åº¦: {emergency_analysis['emergency_level']}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å’Œæ£€ç´¢ç»“æœï¼Œæä¾›ä¸“ä¸šçš„å¿ƒè¡€ç®¡åŒ»å­¦å›ç­”ã€‚
"""

            # ä½¿ç”¨CoTæ¨ç†ç”Ÿæˆå›ç­”
            response = llm_client.generate_response_with_cot(
                user_message=user_message,
                context=context,
                system_prompt=system_prompt
            )

            # å¦‚æœCoTæˆåŠŸï¼Œè¿”å›æœ€ç»ˆç­”æ¡ˆï¼›å¦åˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            if response.get('final_answer'):
                return response['final_answer']
            else:
                return self._generate_fallback_answer(question, references, cardio_analysis, emergency_analysis)

        except Exception as e:
            print(f"LLMæ‰©å±•å›ç­”å¤±è´¥: {e}")
            return self._generate_fallback_answer(question, references, cardio_analysis, emergency_analysis)

    def _generate_fallback_answer(self, question: str, references: List[Dict],
                                cardio_analysis: Dict, emergency_analysis: Dict) -> str:
        """å¤‡ç”¨å›ç­”ç”Ÿæˆæ–¹æ¡ˆ"""

        answer_parts = []

        # 1. åŸºäºæ£€ç´¢ç»“æœçš„æ ¸å¿ƒå›ç­”
        if references:
            answer_parts.append("## ğŸ’Š ä¸“ä¸šè§£ç­”")

            # ä¸»è¦ç­”æ¡ˆ
            main_ref = references[0]
            answer_parts.append(f"**æ ¸å¿ƒä¿¡æ¯**: {main_ref['answer']}")

            # è¡¥å……ä¿¡æ¯
            if len(references) > 1:
                answer_parts.append("\n**ç›¸å…³ä¿¡æ¯**:")
                for ref in references[1:3]:
                    if ref['answer'] != main_ref['answer']:
                        answer_parts.append(f"â€¢ {ref['answer']}")

        # 2. æ€¥ç—‡æç¤º
        if emergency_analysis['emergency_level'] != 'low':
            answer_parts.append(f"\n## âš ï¸ é‡è¦æç¤º")
            answer_parts.append(emergency_analysis['recommendation'])

        # 3. é€šç”¨å»ºè®®
        answer_parts.append("\n## ğŸ“‹ å»ºè®®")
        answer_parts.append("â€¢ å¦‚æœ‰ç–‘é—®ï¼Œè¯·å’¨è¯¢ä¸“ä¸šå¿ƒè¡€ç®¡ç§‘åŒ»ç”Ÿ")
        answer_parts.append("â€¢ å®šæœŸè¿›è¡Œå¿ƒè¡€ç®¡å¥åº·æ£€æŸ¥")
        answer_parts.append("â€¢ ä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼")

        # 4. å…è´£å£°æ˜
        answer_parts.append("\n## ğŸ“‹ é‡è¦å£°æ˜")
        answer_parts.append("ä»¥ä¸Šä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­å’Œæ²»ç–—å»ºè®®ã€‚")

        return "\n".join(answer_parts)

    def get_cardio_statistics(self) -> Dict[str, Any]:
        """è·å–å¿ƒè¡€ç®¡ä¸“ç§‘ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_keywords": sum(len(keywords) for keywords in self.cardio_keywords.values()),
            "keyword_categories": len(self.cardio_keywords),
            "risk_factors": len(self.risk_factors),
            "modifiable_factors": len([f for f in self.risk_factors if f.category == "modifiable"]),
            "emergency_keywords": len(self.emergency_keywords),
            "coverage_areas": [
                "å† å¿ƒç—…åŠæ€¥æ€§å† è„‰ç»¼åˆå¾",
                "é«˜è¡€å‹åŠè¡€å‹ç®¡ç†",
                "å¿ƒå¾‹å¤±å¸¸åŠå¿ƒç”µå¼‚å¸¸",
                "å¿ƒåŠ›è¡°ç«­åŠå¿ƒåŠŸèƒ½ä¸å…¨",
                "å¿ƒè¡€ç®¡é£é™©å› ç´ è¯„ä¼°",
                "å¿ƒè¡€ç®¡æ€¥ç—‡è¯†åˆ«",
                "å¿ƒè¡€ç®¡è¯ç‰©æŒ‡å¯¼",
                "å¿ƒè¡€ç®¡åº·å¤æŒ‡å¯¼"
            ]
        }

        # å¦‚æœæœ‰çŸ¥è¯†åº“ï¼Œæ·»åŠ çŸ¥è¯†åº“ç»Ÿè®¡
        if self.knowledge_base:
            stats.update({
                "knowledge_base_size": len(self.knowledge_base),
                "avg_keywords_per_qa": sum(item.get('keyword_count', 0) for item in self.knowledge_base) / len(self.knowledge_base)
            })

        return stats
