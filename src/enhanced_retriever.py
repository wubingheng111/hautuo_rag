"""
å¢å¼ºæ£€ç´¢å™¨ - æ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥
è§£å†³æ£€ç´¢è¿‡äºæ­»æ¿çš„é—®é¢˜
"""
import re
import jieba
from typing import List, Dict, Any, Optional
from embeddings import EmbeddingManager
from config import settings


class EnhancedRetriever:
    """å¢å¼ºæ£€ç´¢å™¨"""
    
    def __init__(self):
        self.embedding_manager = EmbeddingManager()
        
        # åŒ»å­¦åŒä¹‰è¯æ˜ å°„
        self.medical_synonyms = {
            "é«˜è¡€å‹": ["é«˜å‹", "è¡€å‹é«˜", "è¡€å‹å‡é«˜", "é«˜è¡€å‹ç—…"],
            "ä½è¡€å‹": ["ä½å‹", "è¡€å‹ä½", "è¡€å‹é™ä½", "ä½è¡€å‹ç—‡"],
            "å¿ƒè„ç—…": ["å¿ƒç—…", "å¿ƒè„ç–¾ç—…", "å¿ƒè„é—®é¢˜"],
            "å¿ƒè‚Œæ¢—æ­»": ["å¿ƒæ¢—", "å¿ƒè‚Œæ¢—å¡", "æ€¥æ€§å¿ƒæ¢—"],
            "å¿ƒç»ç—›": ["èƒ¸ç—›", "å¿ƒå‰åŒºç–¼ç—›", "å¿ƒå£ç—›"],
            "å¿ƒå¾‹å¤±å¸¸": ["å¿ƒå¾‹ä¸é½", "å¿ƒè·³ä¸è§„å¾‹", "å¿ƒå¾‹ç´Šä¹±"],
            "å¿ƒåŠ›è¡°ç«­": ["å¿ƒè¡°", "å¿ƒåŠŸèƒ½ä¸å…¨"],
            "å† å¿ƒç—…": ["å† çŠ¶åŠ¨è„‰ç–¾ç—…", "å† çŠ¶åŠ¨è„‰ç—…å˜"],
            "åŠ¨è„‰ç¡¬åŒ–": ["åŠ¨è„‰ç²¥æ ·ç¡¬åŒ–", "è¡€ç®¡ç¡¬åŒ–"],
            "æˆ¿é¢¤": ["å¿ƒæˆ¿é¢¤åŠ¨", "æˆ¿æ€§å¿ƒå¾‹å¤±å¸¸"],
            "èƒ¸é—·": ["èƒ¸éƒ¨ä¸é€‚", "èƒ¸éƒ¨æ†‹é—·"],
            "æ°”çŸ­": ["å‘¼å¸å›°éš¾", "å–˜æ°”", "æ°”ä¿ƒ"],
            "å¿ƒæ‚¸": ["å¿ƒæ…Œ", "å¿ƒè·³å¿«", "å¿ƒè·³åŠ é€Ÿ"]
        }
        
        # å¿ƒè¡€ç®¡å…³é”®è¯
        self.cardio_keywords = [
            "å¿ƒè„", "å¿ƒè¡€ç®¡", "å¿ƒè‚Œ", "å¿ƒæˆ¿", "å¿ƒå®¤", "è¡€å‹", "è¡€ç®¡",
            "åŠ¨è„‰", "é™è„‰", "å† çŠ¶åŠ¨è„‰", "ä¸»åŠ¨è„‰", "è‚ºåŠ¨è„‰",
            "èƒ¸ç—›", "èƒ¸é—·", "å¿ƒæ‚¸", "æ°”çŸ­", "å‘¼å¸å›°éš¾",
            "é«˜è¡€å‹", "ä½è¡€å‹", "å¿ƒå¾‹å¤±å¸¸", "å¿ƒç»ç—›", "å¿ƒè‚Œæ¢—æ­»",
            "å¿ƒåŠ›è¡°ç«­", "å† å¿ƒç—…", "æˆ¿é¢¤", "å¿ƒç”µå›¾", "å¿ƒè„å½©è¶…"
        ]
    
    def preprocess_query(self, query: str) -> List[str]:
        """é¢„å¤„ç†æŸ¥è¯¢ï¼Œç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“"""
        queries = [query]  # åŸå§‹æŸ¥è¯¢
        
        # 1. æ·»åŠ åŒä¹‰è¯å˜ä½“
        for term, synonyms in self.medical_synonyms.items():
            if term in query:
                for synonym in synonyms:
                    variant = query.replace(term, synonym)
                    if variant != query:
                        queries.append(variant)
            
            # åå‘æ›¿æ¢
            for synonym in synonyms:
                if synonym in query:
                    variant = query.replace(synonym, term)
                    if variant != query:
                        queries.append(variant)
        
        # 2. åˆ†è¯åçš„å…³é”®è¯ç»„åˆ
        words = list(jieba.cut(query))
        if len(words) > 1:
            # æå–å¿ƒè¡€ç®¡ç›¸å…³è¯æ±‡
            cardio_words = [w for w in words if any(kw in w for kw in self.cardio_keywords)]
            if cardio_words:
                queries.append(" ".join(cardio_words))
        
        # 3. å»é™¤æ ‡ç‚¹ç¬¦å·çš„ç‰ˆæœ¬
        clean_query = re.sub(r'[^\w\s]', '', query)
        if clean_query != query:
            queries.append(clean_query)
        
        # 4. æ·»åŠ é—®é¢˜æ ¼å¼
        if not query.endswith('ï¼Ÿ') and not query.endswith('?'):
            queries.append(query + "ï¼Ÿ")
        
        return list(set(queries))  # å»é‡
    
    def multi_strategy_search(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """å¤šç­–ç•¥æ£€ç´¢"""
        all_results = []
        
        # ç­–ç•¥1: åŸå§‹æŸ¥è¯¢
        try:
            results1 = self.embedding_manager.search_similar(
                query, 
                top_k=top_k, 
                threshold=0.1  # éå¸¸å®½æ¾çš„é˜ˆå€¼
            )
            for result in results1:
                result['strategy'] = 'original'
                result['boost'] = 1.0
            all_results.extend(results1)
        except Exception as e:
            print(f"åŸå§‹æŸ¥è¯¢å¤±è´¥: {e}")
        
        # ç­–ç•¥2: æŸ¥è¯¢å˜ä½“
        query_variants = self.preprocess_query(query)
        for i, variant in enumerate(query_variants[1:], 1):  # è·³è¿‡åŸå§‹æŸ¥è¯¢
            try:
                results = self.embedding_manager.search_similar(
                    variant, 
                    top_k=max(5, top_k//2), 
                    threshold=0.1
                )
                for result in results:
                    result['strategy'] = f'variant_{i}'
                    result['boost'] = 0.8  # å˜ä½“æƒé‡ç¨ä½
                all_results.extend(results)
            except Exception as e:
                print(f"å˜ä½“æŸ¥è¯¢å¤±è´¥ ({variant}): {e}")
        
        # ç­–ç•¥3: å…³é”®è¯æ£€ç´¢
        keywords = self.extract_keywords(query)
        if keywords:
            keyword_query = " ".join(keywords)
            try:
                results3 = self.embedding_manager.search_similar(
                    keyword_query, 
                    top_k=max(5, top_k//2), 
                    threshold=0.05  # æ›´å®½æ¾
                )
                for result in results3:
                    result['strategy'] = 'keywords'
                    result['boost'] = 0.6
                all_results.extend(results3)
            except Exception as e:
                print(f"å…³é”®è¯æŸ¥è¯¢å¤±è´¥: {e}")
        
        # åˆå¹¶å’Œå»é‡
        unique_results = self.merge_and_deduplicate(all_results)
        
        # é‡æ–°æ’åº
        final_results = self.rerank_results(unique_results, query)
        
        return final_results[:top_k]
    
    def extract_keywords(self, query: str) -> List[str]:
        """æå–å…³é”®è¯"""
        words = list(jieba.cut(query))
        
        # è¿‡æ»¤åœç”¨è¯
        stop_words = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'å¦‚æœ', 'å› ä¸º', 'æ‰€ä»¥', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å—', 'å‘¢', 'å§'}
        
        keywords = []
        for word in words:
            if len(word) > 1 and word not in stop_words:
                keywords.append(word)
        
        # ä¼˜å…ˆä¿ç•™åŒ»å­¦ç›¸å…³è¯æ±‡
        medical_keywords = [w for w in keywords if any(kw in w for kw in self.cardio_keywords)]
        other_keywords = [w for w in keywords if w not in medical_keywords]
        
        return medical_keywords + other_keywords[:3]  # åŒ»å­¦è¯æ±‡ + æœ€å¤š3ä¸ªå…¶ä»–è¯æ±‡
    
    def merge_and_deduplicate(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åˆå¹¶å’Œå»é‡ç»“æœ"""
        seen_texts = set()
        unique_results = []
        
        for result in results:
            text = result.get('text', '')
            # ä½¿ç”¨æ–‡æœ¬çš„å‰100ä¸ªå­—ç¬¦ä½œä¸ºå»é‡æ ‡è¯†
            text_key = text[:100]
            
            if text_key not in seen_texts:
                seen_texts.add(text_key)
                unique_results.append(result)
        
        return unique_results
    
    def rerank_results(self, results: List[Dict[str, Any]], query: str) -> List[Dict[str, Any]]:
        """é‡æ–°æ’åºç»“æœ"""
        query_lower = query.lower()
        
        for result in results:
            text = result.get('text', '').lower()
            metadata = result.get('metadata', {})
            
            # åŸºç¡€åˆ†æ•°
            base_score = result.get('similarity', 0) * result.get('boost', 1.0)
            
            # æ–‡æœ¬åŒ¹é…åŠ åˆ†
            text_bonus = 0
            for word in jieba.cut(query_lower):
                if len(word) > 1 and word in text:
                    text_bonus += 0.1
            
            # å…³é”®è¯åŒ¹é…åŠ åˆ†
            keyword_bonus = 0
            keywords = metadata.get('keywords', '')
            if keywords:
                for word in jieba.cut(query_lower):
                    if len(word) > 1 and word in keywords.lower():
                        keyword_bonus += 0.15
            
            # é—®é¢˜ç±»å‹åŒ¹é…åŠ åˆ†
            question = metadata.get('question', '').lower()
            if question:
                # å¦‚æœæŸ¥è¯¢å’Œé—®é¢˜æœ‰ç›¸ä¼¼çš„ç»“æ„
                if any(marker in query_lower for marker in ['ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å¦‚ä½•']):
                    if any(marker in question for marker in ['ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å¦‚ä½•']):
                        text_bonus += 0.2
            
            # è®¡ç®—æœ€ç»ˆåˆ†æ•°
            final_score = base_score + text_bonus + keyword_bonus
            result['final_score'] = final_score
        
        # æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº
        return sorted(results, key=lambda x: x.get('final_score', 0), reverse=True)
    
    def search(self, query: str, top_k: int = None, debug: bool = False) -> List[Dict[str, Any]]:
        """ä¸»è¦æœç´¢æ¥å£"""
        top_k = top_k or settings.TOP_K_RETRIEVAL
        
        if debug:
            print(f"ğŸ” åŸå§‹æŸ¥è¯¢: {query}")
            variants = self.preprocess_query(query)
            print(f"ğŸ”„ æŸ¥è¯¢å˜ä½“: {variants}")
            keywords = self.extract_keywords(query)
            print(f"ğŸ”‘ æå–å…³é”®è¯: {keywords}")
        
        # ä½¿ç”¨å¤šç­–ç•¥æ£€ç´¢
        results = self.multi_strategy_search(query, top_k)
        
        if debug:
            print(f"ğŸ“Š æ£€ç´¢ç»“æœæ•°é‡: {len(results)}")
            for i, result in enumerate(results[:3], 1):
                print(f"   {i}. åˆ†æ•°: {result.get('final_score', 0):.3f}, ç­–ç•¥: {result.get('strategy', 'unknown')}")
                print(f"      æ–‡æœ¬: {result.get('text', '')[:100]}...")
        
        return results
